# CSCA-5642 Final Project

This project explores the application of deep neural networks for human action recognition (HAR) in video sequences. Human action recognition has a wide range of practical applications, including sports analytics, robotics, and surveillance systems. By leveraging architectures such as 3D Convolutional Networks, this study aims to compare the effectiveness of different algorithmic designs. Key challenges include modeling long-term temporal dependencies and handling variations in video length, lighting conditions, and resolution.


## Directory Structure
Below is the directory structure of the project:

  ├── data/<br>
  │    ├── v_ApplyEyeMakeup_g01_c01.avi<br>
  │    ├── ...<br>
  │    └── v_ApplyLipstick_g01_c01.avi<br>
  └── video-action-recognition-classification-final-project.ipynb<br>


## Files
- data/xxx.avi: Same avi file from the UCF (University of Central Florida) Action Recognition Data Set.
- Video-Action-Classifier.ipynb: The main Jupyter Notebook containing the Convolutional 3D code. 

## Author
- **Author**: Alexander Meau
- **Email**: alme9155@colorado.edu
